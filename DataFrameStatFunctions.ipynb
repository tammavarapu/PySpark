{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrameStatFunctions: statistic functions with DataFrame\n",
    "=======================\n",
    "approxQuantile(col, probabilities, relativeError)\n",
    "\n",
    "corr()\n",
    "\tCalculates the correlation of two columns of a DataFrame as a double value. Currently only supports the Pearson Correlation Coefficient. \n",
    "\tDataFrame.corr() and DataFrameStatFunctions.corr() are aliases of each other.\n",
    "\n",
    "\t\n",
    "cov(col1, col2)\n",
    "\tCalculate the sample covariance for the given columns, specified by their names, as a double value. \n",
    "\tDataFrame.cov() and DataFrameStatFunctions.cov() are aliases.\n",
    "\t\n",
    "\n",
    "crosstab(col1, col2)\n",
    "\tComputes a pair-wise frequency table of the given columns\n",
    "\tDataFrame.crosstab() and DataFrameStatFunctions.crosstab() are aliases.\n",
    "\t\n",
    "\t\n",
    "freqItems(cols, support=None)\n",
    "\tFinding frequent items for columns, possibly with false positives\n",
    "\n",
    "sampleBy(col, fractions, seed=None)\n",
    "\tReturns a stratified sample without replacement based on the fraction given on each stratum.\n",
    "\t\n",
    "from pyspark.sql.functions import col\n",
    "dataset = sqlContext.range(0, 100).select((col(\"id\") % 3).alias(\"key\"))\n",
    "sampled = dataset.sampleBy(\"key\", fractions={0: 0.1, 1: 0.2}, seed=0)\n",
    "sampled.groupBy(\"key\").count().orderBy(\"key\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
