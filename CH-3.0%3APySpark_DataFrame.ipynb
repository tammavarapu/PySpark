{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark 1.6 began with the RDD and that syntax kittle tricky to learn.\n",
    "Later Spark 2.0 and higher has shifted to Dataframes. \n",
    "Now Spark 3.0 comes with Delta Lake with this we can run ACID transactions. \n",
    "\n",
    "Spark Dataframes hold data in a column and row format.\n",
    "Each column represents some features and variables.\n",
    "Each row represents an individual data point.\n",
    "\n",
    "Note: Spark Dataframe handle missing data with null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark 3.x\n",
    "=========\n",
    "Language support: Python3,Scala 2.12,fully support JDK 11 and  Python 2.x deprecated.\n",
    "Adaptive execution of Spark SQL\n",
    "Dynamic Partition Pruning (DPP)\n",
    "Enhanced Support for Deep Learning\n",
    "Better Kubernetes Integration\n",
    "Graph features\n",
    "ACID Transactions with Delta Lake\n",
    "Growing integration with Apache Arrow data format\n",
    "Binary files data source\n",
    "DataSource V2 Improvements\n",
    "YARN Features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
